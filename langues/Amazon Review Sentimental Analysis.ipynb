{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "import string\n",
    "from collections import Counter\n",
    "string.punctuation\n",
    "stopwords.words('english')\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_raw = pd.read_csv('amazon-fine-food-reviews/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = review_raw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(s):\n",
    "    return s.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    return [word for word in text if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lem(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_tokens = [lemmatizer.lemmatize(token.decode('utf-8')) for token in tokens]\n",
    "    return lem_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/changtao/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/changtao/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "review.loc[:, 'token'] = review['Text'].apply(lambda s : str(s).lower()).apply(remove_punc).apply(word_tokenize)\n",
    "review.loc[:, 'token'] = review['token'].apply(lem)\n",
    "review.loc[:, 'token'] = review['token'].map(lambda s : ' '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab = 20000\n",
    "vocab_size = max_vocab + 1\n",
    "maxlen = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "\n",
    "    Y = df['Score']\n",
    "\n",
    "    sentences = []\n",
    "    for s in df['token']:\n",
    "        sentences.append(s)\n",
    "\n",
    "    sentences = [s.split(' ') for s in sentences]\n",
    "    word_counts = Counter(itertools.chain(*sentences))\n",
    "    vocabulary_inv = [x[0] for x in word_counts.most_common(max_vocab)]\n",
    "    vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "    vocabulary = {x : i + 1 for i, x in enumerate(vocabulary_inv)}\n",
    "\n",
    "    X = np.array([[vocabulary.get(word) for word in sentence if word in vocabulary] for sentence in sentences])\n",
    "    X = sequence.pad_sequences(X, maxlen = maxlen)\n",
    "\n",
    "    return X, Y, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, vocabulary = prepare_features(review)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=maxlen))\n",
    "model.add(LSTM(25))\n",
    "model.add(Dense(12))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 397888 samples, validate on 170524 samples\n",
      "Epoch 1/1\n",
      "397888/397888 [==============================] - 114s - loss: 1.0567 - mean_squared_error: 1.0567 - val_loss: 0.7221 - val_mean_squared_error: 0.7221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f303dfee190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test, verbose = 0)\n",
    "y_test_pred.shape = (X_test.shape[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89, Recall: 0.96, Precision: 0.90, F1 Score: 0.93, AUC: 0.79\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score((y_test > 3.0).astype(int), (y_test_pred > 3.0).astype(int))\n",
    "recall = metrics.recall_score((y_test > 3.0).astype(int), (y_test_pred > 3.0).astype(int))\n",
    "precision = metrics.precision_score((y_test > 3.0).astype(int), (y_test_pred > 3.0).astype(int))\n",
    "f1score = metrics.f1_score((y_test > 3.0).astype(int), (y_test_pred > 3.0).astype(int))\n",
    "auc = metrics.roc_auc_score((y_test > 3.0).astype(int), (y_test_pred > 3.0).astype(int))\n",
    "print 'Accuracy: %.2f, Recall: %.2f, Precision: %.2f, F1 Score: %.2f, AUC: %.2f' % (acc, recall, precision, f1score, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23185,  14197],\n",
       "       [  4705, 128437]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix((y_test > 3.0).astype(int), (y_test_pred > 3.0).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
